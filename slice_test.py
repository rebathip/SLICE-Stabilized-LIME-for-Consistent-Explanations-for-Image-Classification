# -*- coding: utf-8 -*-
"""slice.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1d93sHxTgwIzLe2BjkP0r1PgqzNBSi_9F
"""

import os
import pickle
import numpy as np
import cv2
import keras
from keras.applications.imagenet_utils import decode_predictions
import skimage.io
from skimage.segmentation import quickshift, mark_boundaries
from skimage.measure import regionprops
import copy
import random
import sklearn
import sklearn.metrics
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import Ridge
from skimage import filters
import pandas as pd
import warnings
import tensorflow as tf
import pickle
import sys
from scipy.stats import kendalltau

from matplotlib import pyplot as plt
import time
from sklearn.utils import resample
from scipy.stats import norm, gaussian_kde
from sklearn.neighbors import KernelDensity
import csv
from slice.slice_explainer import SliceExplainer
from slice.vit_img_classifier import ViTImageClassifier
#from transformers import ViTFeatureExtractor, TFViTForImageClassification


#Usage
img_dir = "images_oxpets/"
try:
    img_filenames = os.listdir(img_dir)
except IndexError:
    print("No files found in the directory.")

algo_name = "slice"
results_dir = "results/"
num_runs = 20
sample_size = 500
tol = 3 # tolerance parameter for feature elimination algorithm

#resnet50
#model = tf.keras.applications.resnet50.ResNet50(weights='imagenet')
#preprocess_input = tf.keras.applications.resnet.preprocess_input
#decode_predictions = tf.keras.applications.resnet.decode_predictions
#target_img_size = (224, 224)

#ViT
#model_name = "google/vit-base-patch16-224"
#model = ViTImageClassifier(model_name)
#preprocess_input = model.preprocess_image
#target_img_size = (224,224)

#inceptionv3
model = tf.keras.applications.InceptionV3(weights='imagenet')
preprocess_input = tf.keras.applications.inception_v3.preprocess_input
decode_predictions = tf.keras.applications.inception_v3.decode_predictions
target_img_size = (299, 299)

model_name = model.name
model_name = model_name.replace("_", "")

for img_filename in img_filenames:
    img_dict = {}
    img_dir_name = (img_dir.split("_")[1]).split("/")[0]
    img_filename_split = (img_filename.split(".jpg") if ".jpg" in img_filename else img_filename.split(".png"))[0]

    pkl_filename = results_dir + img_dir_name + "/" + algo_name + "_" + model_name + "/" + img_dir_name + "_" + \
                   algo_name + "_" + img_filename_split + "_" + model_name + ".pkl"
    print(pkl_filename) # the sub-dir inside results_dir should be present
    if os.path.exists(pkl_filename):
        continue

    seg_img = skimage.io.imread(img_dir + img_filename)
    seg_img = skimage.transform.resize(seg_img, target_img_size)
    # too many segments will increase the computation time
    segments = skimage.segmentation.quickshift(seg_img, kernel_size=5, max_dist=200, ratio=0.2,
                                               random_seed=42)
    exp = SliceExplainer(image_path=img_dir + img_filename, segments=segments, model=model, \
                         target_img_size=target_img_size, preprocess=preprocess_input)
    sel_sigma = exp.select_sigma() # normally 0.3 works in most cases
    del exp

    print("sel_sigma:" + str(sel_sigma))
    run_dict = {}
    for i in np.arange(0, num_runs, step=1):
        # image_path=img_dir + img_filename
        exp = SliceExplainer(image_path=img_dir + img_filename, segments=segments, model=model, \
                             target_img_size=target_img_size, preprocess=preprocess_input)
        print(img_filename, " : ", len(np.unique(exp.superpixels)), " : ", sample_size)
        unstable_features, pos_feature_ranks, neg_feature_ranks, num_samples_used, pos_dict, neg_dict\
            = exp.get_slice_explanations(num_perturb=sample_size, tolerance_limit=tol, sigma=sel_sigma,
                                         rank_stabilization=False)

        print("pos: " + str(pos_feature_ranks))
        print("neg: " + str(neg_feature_ranks))

        ranks = {'pos': pos_feature_ranks.astype('int') if len(pos_feature_ranks) > 0 else np.array([]),
                 'neg': neg_feature_ranks.astype('int') if len(neg_feature_ranks) > 0 else np.array([]),
                 'pos_dict': pos_dict, 'neg_dict': neg_dict, 'sel_sigma': sel_sigma,
                 'h_unstable': unstable_features, 'num_samples': num_samples_used}

        if f'run_{i}' not in run_dict:
            run_dict[f'run_{i}'] = []

        del exp
        #
        run_dict[f'run_{i}'].append(ranks)
        img_key = img_filename.split('.')[0]

    if f'run_{img_key}' not in img_dict:
        img_dict[f'run_{img_key}'] = []

    img_dict[f'run_{img_key}'].append(run_dict)

    # # save the selected feature ranks in a dict and save it in a pkl file
    print(pkl_filename)
    with open(pkl_filename, 'wb') as f1:
        pickle.dump(img_dict, f1)
